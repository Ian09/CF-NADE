{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Network Parameters\n",
    "movie_num = 3883\n",
    "score_num = 5 \n",
    "batch_size = 512\n",
    "hidden_num = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = tf.placeholder(tf.float32, shape=[None, movie_num, score_num])\n",
    "in_mask = tf.placeholder(tf.float32, shape=[None, movie_num])\n",
    "out_mask = tf.placeholder(tf.float32, shape=[None, movie_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CF_NADE(ratings, in_mask, out_mask):\n",
    "    bias = {'l1':tf.Variable(tf.random_normal(shape=[hidden_num])),\n",
    "           'l2':tf.Variable(tf.random_normal(shape=[movie_num, score_num]))}\n",
    "    weight = {'l1':tf.Variable(tf.random_normal(shape=[movie_num, score_num, hidden_num])),\n",
    "             'l2':tf.Variable(tf.random_normal(shape=[hidden_num, movie_num, score_num]))}\n",
    "    # dim(h) = batch_size * hidden_num\n",
    "    h = tf.tanh(tf.add(bias['l1'], tf.tensordot(ratings\n",
    "                                                * in_mask[:,:,np.newaxis], weight['l1'], axes=[[1,2], [0,1]])))\n",
    "    #dim(output) = batch_size * movie_num * socre_num\n",
    "    output = tf.add(bias['l2'], tf.tensordot(h, weight['l2'], axes=[[1], [0]]) * out_mask[:,:,np.newaxis])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = CF_NADE(ratings, in_mask, out_mask)\n",
    "#dim(scores_tensor) = batch_size * movie_num * score_num\n",
    "scores_tensor = np.concatenate([np.ones((batch_size, movie_num, 1)) * i for i in range(1, 6)], axis=2)\n",
    "#dim(batch_socres) = batch_size * movie_num\n",
    "pred_scores = tf.reduce_sum(scores_tensor * tf.nn.softmax(output, axis=2), axis=2)\n",
    "true_scores = tf.argmax((ratings * out_mask[:,:,np.newaxis]), axis=2) + 1\n",
    "loss_op = tf.losses.mean_squared_error(true_scores, pred_scores)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epoches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ae8108f335b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loop_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_epoch_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# to do\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mratings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epoches' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epoches):\n",
    "        for batch in train_loop_stream.get_epoch_iterator(): # to do\n",
    "            ratings, in_mask, out_mask = batch\n",
    "            sess.run(train_op, feed_dict={ratings:ratings, in_mask:in_mask, out_mask:out_mask})\n",
    "        loss = sess.run(loss_op, feed_dict={ratings:ratings, in_mask:inmask, out_mask:outmask})\n",
    "        print ('epoch:', epoch, 'loss:', loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
